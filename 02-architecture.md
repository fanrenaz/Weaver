# FamilyAthena 后端系统架构设计（MVP 极简版 / Python + LangChain / 无鉴权版本 / 全部记忆托管给 LangChain / 必须双人绑定）

版本: 1.0-MVP-Simplified-NoAuth-LCMemory-V2  
更新说明：  
- 取消单人模式：对话只能在 pair 双方均已绑定后开始；未完成绑定时禁止发送消息  
- 不再对 LangChain Summarizer 输出格式施加结构化约束；使用其默认摘要行为，摘要文本原样存储  
- 继续保持：无鉴权、无异步队列、无日志观测、无自定义上下文裁剪逻辑、无代码示例

---

## 1. 目标范围

实现最小闭环（前置条件：双方已绑定）：  
1. 参与者 A 创建绑定邀请，参与者 B 加入完成 pair  
2. 双方均可向共享 AI 会话发送消息  
3. 连续对话的上下文记忆、裁剪与摘要全部由 LangChain 内部记忆组件自动处理  
4. 每次 AI 回复体现对双方历史的抽象连续理解（不逐字引用对方原文）

不做：鉴权、速率限制、监控、异步任务、成本/统计、向量检索、模型降级策略、单人对话。

---

## 2. 高层结构（单进程）

- HTTP 服务层：提供邀请/加入、消息发送、消息查询、摘要查询  
- 内存态 Memory 管理：为每个已完成绑定的 pair 维护一个 LangChain Memory 实例  
- LangChain：使用“总结 + 缓冲”记忆组件（如 ConversationSummaryBufferMemory）自动触发摘要与裁剪  
- sqlite：持久化 pair / 邀请码 / 消息 / 摘要（最新摘要文本版本）  
- 冷启动：按需从数据库重建指定 pair 的 Memory（最新摘要 + 最近消息）  

---

## 3. 对话启动前置条件

- pair 只有在 participant_a 与 participant_b 均存在且状态=已绑定后才允许发送消息  
- 若尝试在未完成绑定前发送消息，直接返回错误  
- 不缓存“单人阶段”消息；也不允许“预发送”排队

---

## 4. 记忆与上下文（完全 LangChain 托管）

- 使用 LangChain 内置记忆组件的默认摘要触发（基于 token / 长度）  
- 系统不实现消息条数或时间阈值触发逻辑  
- 组件内部产生新的摘要后，可被检测（比较当前摘要文本与上次持久化版本）并保存为 Snapshot  
- 应用不解析摘要结构；仅做纯文本持久化

---

## 5. 摘要策略（无格式约束）

- 不强制 topics / consensus / divergences / info_gaps 结构  
- 摘要形式由模型与 LangChain 默认 prompt 决定  
- 系统仅要求摘要不应包含对另一方逐字复制（若出现，由后续迭代再处理；当前 MVP 不拦截）  
- 存储：最新摘要每次变化即追加版本（可采用简单递增版本号）

---

## 6. 数据模型（概念）

- Pair：id，participant_a_id，participant_b_id，状态（pending / active），创建时间  
- InviteCode：code，关联发起者，过期时间，使用时间  
- Message：id，pair_id，sender_type（USER/AI），sender_participant_id（AI 为空），内容，时间，模型名称（保留字段），顺序  
- Snapshot：id，pair_id，版本号，摘要文本，创建时间  

未绑定时仅允许存在 Pair 与 InviteCode 记录；Message / Snapshot 只能隶属于 active 状态 pair。

---

## 7. 消息发送流程（仅 active pair）

1. 校验 pair 状态=active  
2. 写入用户消息（持久化）  
3. 获取/创建该 pair 的内存态 Memory：若首次则重建（加载最新摘要 + 最近消息窗口）  
4. 将本用户消息注入 Memory  
5. 调用模型生成 AI 回复（Memory 自动附带历史/摘要）  
6. 按流式向客户端输出 AI 内容片段（架构描述中不展开细节）  
7. 回复完成后持久化 AI 消息并注入 Memory  
8. 检测 Memory 当前摘要文本是否与数据库最新 Snapshot 不同：  
   - 若不同：保存新 Snapshot（版本 +1）  

---

## 8. 冷启动 / 重建策略

- 当进程首次处理某 active pair：  
  1. 读取最新 Snapshot（若存在）  
  2. 读取最近固定数量消息（如 40 条；纯概念约束）  
  3. 依时间顺序注入 Memory（用户/AI 交替）  
  4. 准备好后继续本轮消息流程  
- 若 Snapshot 不存在（说明尚未触发内部摘要），仅注入最近消息

---

## 9. API（概念）

- POST /pair/invite  创建 pending pair + 邀请码  
- POST /pair/join    使用邀请码将第二参与者绑定 → 状态变为 active  
- GET  /pair/status  查询 pair 状态  
- POST /messages     （要求 pair active）发送消息并获得流式回复  
- GET  /messages     分页查询历史（按时间正序或倒序明确定义）  
- GET  /memory/snapshot 返回最新已持久化摘要（无则空）

错误最小化分类：pair_not_active / invite_invalid / model_error / internal_error。

---

## 10. 并发与一致性取舍

- 假设低并发；两个参与者同时发送消息时可能出现 Memory 瞬时重建竞态  
- 简化处理：若内存中无现成 Memory，任何一个请求都可重建；重复重建的开销在 MVP 中可接受  
- 摘要落库冲突：若同时检测到变化并保存，出现两个接近时间的版本亦可接受，不做去重

---

## 11. 失败场景（最小）

- 模型调用失败：返回错误，不写入 AI 消息，不更新摘要  
- 摘要保存失败：忽略，不回滚对话流程；下次摘要变化再尝试  
- sqlite 写入锁冲突（极少）：简单重试（架构描述阶段无需细节）

---

## 12. 性能假设

- 活跃 pair 数量极低（实验初期）  
- 每次对话使用内存中的已裁剪上下文 → token 控制由 LangChain 内部参数保障  
- 摘要生成频率受 token_limit 自动调节，整体额外开销可忽略  
- 单文件 sqlite 足以支撑最初阶段；后续增长再评估迁移

---

## 13. 安全与隐私（最小提示）

- 无鉴权 → 所有安全风险暂不处理（包括伪造参与者 ID / 邀请码暴力尝试）  
- 后续若添加鉴权需重新评估数据访问控制与日志审计

---

## 14. 风险与扩展路径

风险  
- 无单人模式可能降低早期试用便利（需产品确认）  
- 摘要自由格式可能造成后续结构化分析困难  
- 内存态依赖单进程；多实例扩展需重新设计 Memory 持久化或实时重建

扩展路径  
- 引入鉴权与基础速率限制  
- 后期为摘要添加结构化输出要求  
- 支持多进程：改为“每请求即时重建上下文”或持久化 Memory 状态  
- 接入向量索引实现更长程检索

---

## 15. 验收标准

- 未完成绑定时发送消息返回 pair_not_active  
- 完成绑定后双方互发多轮消息，AI 回复能引用另一方观点（概述形式，非逐字）  
- 累积对话后出现至少一个新增 Snapshot 版本（摘要文本变化）  
- 服务重启后再次发送消息仍能保持连续感（说明重建逻辑生效）  
- 消息分页结果顺序一致且不重复、不缺失

---

## 16. 实施优先级

1. 数据表（pair / invite / message / snapshot）  
2. 邀请 / 加入流程（状态变更到 active）  
3. LangChain Memory 集成（单模型）  
4. 消息发送 + 流式回复 + 持久化  
5. 摘要变化检测与 Snapshot 保存  
6. 冷启动重建逻辑  
7. 消息与摘要查询  
8. 基础错误处理与手工测试

---

## 17. 成功标记

达到以下全部即视为 MVP 完成：  
- 成功创建与激活 pair  
- 双方可稳定收发 ≥10 轮对话  
- 过程中至少一次自动摘要生成并持久化  
- 重启后继续对话连续性可感知  
- 无单人对话通道被误开启

---

本版本文件已按要求移除单人模式支持与摘要格式约束，保持极简实现路径，专注验证“双人共享上下文对话”核心价值。
